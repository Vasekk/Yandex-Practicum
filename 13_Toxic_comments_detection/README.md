# Обнаружение токсичных комментариев

## Постановка задачи

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

Необходимо обучить модель классифицировать комментарии на позитивные и негативные. В распоряжении набор данных с разметкой о токсичности правок.

Построить модель со значением метрики качества *F1* не меньше 0.75. 

## Данные

Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак.

## План исследования:

1. Загрузите и подготовьте данные.
2. Обучите разные модели. 
3. Сделайте выводы.

Для исследования использованы библиотеки Pandas, sklearn, nltk, re, pattern

## Итоги исследования 

1. Выполнена загрузка данных, подготовлены признаки для обучения.

2. С использованием пайплайнов и кросс-валидации проверено качество моделей LogisticRegression, DecisionTreeClassifier, LogisticRegression. Лучшая модель - LogisticRegression с подобранными гиперпараметрами (solver='saga', penalty='l1') имеет cv_F1 = 0.7596. На тестовой выборке модель имеет метрику 0.7851. Для сравнения F1 константной модели равна 0.1845 

3. Разработанная модель позволит выявлять токсичные комментарии и отправлять их на модерацию.

